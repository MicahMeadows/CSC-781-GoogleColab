{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMaWAc/fbX2EOhWDKdb06C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MicahMeadows/CSC-781-GoogleColab/blob/main/Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression\n",
        "Logistic regression is a way to figure out if one thing can predict if something else will happen. It's used in lots of different areas like money, health, and marketing. In this report, we'll use the \"sklearn breast cancer\" dataset to learn more about logistic regression and how it can be useful.\n",
        "\n",
        "Difference between Logistic Regression and Linear Regression:\n",
        "\n",
        "Linear regression and logistic regression are different because they look at different kinds of things. Linear regression is used when we want to predict a number, like how much money someone will make. Logistic regression is used when we want to predict if something will happen or not, like if someone will get cancer or not. Linear regression gives us a straight line, but logistic regression gives us a curve that looks like an S. Also, linear regression has something called \"normal distribution\", which is different than what logistic regression has."
      ],
      "metadata": {
        "id": "OjMMNt_QTh8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets # dataset\n",
        "from sklearn.metrics import roc_auc_score # scoring\n",
        "from sklearn.model_selection import train_test_split # data manipulation\n",
        "import numpy as np # data manipulation"
      ],
      "metadata": {
        "id": "atAYUGpiO_Oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sigmoid\n",
        "Our sigmoid function will be used in order to determine the cost value of an input, the sigmoid function is the S shaped function that grades our input between 0 and 1. Generally, a result towards 0 will be 0 and 1 will be 1, however it is also possible to change the boundary so for instance anything about .7 will result in 1 and anything below will be 0."
      ],
      "metadata": {
        "id": "GNwxcTkUUHNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "JqbDgkX2PBbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression Model\n",
        "Here we have our custom Logistic Regression Model, using this model we can fit our logistic regression to give us our accurate (hopefully) prediction."
      ],
      "metadata": {
        "id": "E3tCeLSFUdaQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65zXCdKmMth1"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression:\n",
        "  def __init__(self, lr=.001, n_iters=1000):\n",
        "    self.lr = lr\n",
        "    self.n_iters = n_iters\n",
        "    self.weights = None\n",
        "    self.bias = None\n",
        "  \n",
        "  def fit(self, X, y):\n",
        "    n_samples, n_features = X.shape\n",
        "    self.weights = np.zeros(n_features)\n",
        "    self.bias = 0\n",
        "\n",
        "    for _ in range(self.n_iters):\n",
        "      linear_preds = np.dot(X, self.weights) + self.bias\n",
        "      preds = sigmoid(linear_preds)\n",
        "\n",
        "      dw = (1 / n_samples) * np.dot(X.T, (preds - y))\n",
        "      db = (1 / n_samples) * np.sum(preds - y)\n",
        "\n",
        "      self.weights = self.weights - self.lr * dw\n",
        "      self.bias = self.bias - self.lr * db\n",
        "    \n",
        "  def predict(self, X):\n",
        "    linear_pred = np.dot(X, self.weights) + self.bias\n",
        "    y_pred = sigmoid(linear_pred)\n",
        "    class_pred = [0 if y < .5 else 1 for y in y_pred]\n",
        "    return class_pred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data setup\n",
        "Here we will import the breast cancer dataset from sklearn and split it into training and testing data"
      ],
      "metadata": {
        "id": "imUaOksTUlh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bc = datasets.load_breast_cancer()\n",
        "X, y = bc.data, bc.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1234)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHC_fjawOrEY",
        "outputId": "ba752658-c140-4849-fd3c-94b21b9fc32a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-ebbe1fbd659a>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-x))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Regression!\n",
        "This is where we use our regression model to predict our test data!"
      ],
      "metadata": {
        "id": "iEfRQJ1gUt4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(lr=.01)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "0GiWa7tbUrjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Scoring Methods\n",
        "accuracy(): used in order to check how many of the predictions are correct, the first input is the predicted values, the second input is the actual values.\n",
        "\n",
        "auc_score(): used to check the Area Under Curve test, the first input is the predicted values, the second input is the actual values."
      ],
      "metadata": {
        "id": "XtNLumB8U-ol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_pred, y_test):\n",
        "  return np.sum(y_pred == y_test) / len(y_test)\n",
        "\n",
        "def auc_score(y_pred, y_test):\n",
        "  score = roc_auc_score(y_pred, y_test)\n",
        "  return score"
      ],
      "metadata": {
        "id": "1TCyfbXxTMIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Running Scoring\n",
        "Below we can see our testing data scored decently well for predicting the breast cancer. We can see with our regular scoring we achieved a 92.1% accuracy and with the AUC test we get 92.3%!\n",
        "\n",
        "These results are decent for our simple test however with about an 8% chance for innacuracy I would likely not use this method to actually determine if patients have breast cancer."
      ],
      "metadata": {
        "id": "88Qd_lsdVM0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = accuracy(y_pred, y_test)\n",
        "print(f'accuracy: {acc}')\n",
        "\n",
        "auc = auc_score(y_pred, y_test)\n",
        "print(f'auc score: {auc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-12ZB9OXTPYw",
        "outputId": "d1ac4d59-d093-40db-da40-2bb0393fcd60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.9210526315789473\n",
            "auc score: 0.9226190476190476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "In conclusion, we have explored logistic regression and its use in predicting binary outcomes. By using the sklearn breast cancer dataset, we can understand how logistic regression can help us identify potential cases of breast cancer based on various factors. Logistic regression is a powerful tool with a wide range of applications in fields like finance, healthcare, marketing, and more. Understanding logistic regression and its capabilities can help us make better-informed decisions in a variety of contexts."
      ],
      "metadata": {
        "id": "ZP-ytmXeVoGm"
      }
    }
  ]
}